{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "969bd85a-898b-45eb-a05e-a0ef08b94b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tensorflow_io provides extended data formats and\n",
    "# the ability to stream data\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b99532a8-22da-454e-a8f0-0db5be2c1ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples in slice:  480000\n"
     ]
    }
   ],
   "source": [
    "contents = os.getcwd() + '/tronica_trimmed.wav'\n",
    "sample_rate = 48000\n",
    "# in number of seconds\n",
    "slice_length = 10\n",
    "# number of samples we will use for our slices\n",
    "s_len = sample_rate*slice_length\n",
    "print(\"samples in slice: \", s_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef55072",
   "metadata": {},
   "source": [
    "The Below code will take the sample and split it into two stereo samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "acc214de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment from pydub\n",
    "from pydub import AudioSegment\n",
    "  \n",
    "# Open the stereo audio file as\n",
    "# an AudioSegment instance\n",
    "stereo_audio = AudioSegment.from_file(\n",
    "    contents,\n",
    "    format=\"wav\")\n",
    "\n",
    "# read the audio file into an IOTensor\n",
    "audio = tfio.audio.AudioIOTensor(contents)\n",
    "# slice the audio tensor into a bunch of tensors that are each 10 seconds long\n",
    "\n",
    "audio_slice = audio\n",
    "print(audio_slice)\n",
    "Audio(audio[:1].numpy(), rate=audio.rate.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d103b622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathan/workspace/tensor_flow_projects/audio_experiments/tronica_trimmed_left.wav\n",
      "/Users/nathan/workspace/tensor_flow_projects/audio_experiments/tronica_trimmed_right.wav\n"
     ]
    }
   ],
   "source": [
    "# Calling the split_to_mono method\n",
    "# on the stereo audio file\n",
    "mono_audios = stereo_audio.split_to_mono()\n",
    "  \n",
    "# Exporting/Saving the two mono\n",
    "# audio files present at index 0(left)\n",
    "# and index 1(right) of list returned\n",
    "# by split_to_mono method\n",
    "left_path = contents[:-4]+\"_left.wav\"\n",
    "right_path = contents[:-4]+\"_right.wav\"\n",
    "print(left_path)\n",
    "print(right_path)\n",
    "\n",
    "mono_left = mono_audios[0].export(\n",
    "    left_path,\n",
    "    format=\"wav\")\n",
    "mono_right = mono_audios[1].export(\n",
    "    right_path,\n",
    "    format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f0e7b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AudioIOTensor: shape=[2425819       2], dtype=<dtype: 'int16'>, rate=48000>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1102, in __len__\n\nTypeError: Scalar tensor has no `len()`\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(audio_slice)\n\u001b[0;32m----> 2\u001b[0m slice_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32768.0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(slice_tensor)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# add a fade out at the start and end\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1102, in __len__\n\nTypeError: Scalar tensor has no `len()`\n\n"
     ]
    }
   ],
   "source": [
    "print(audio_slice)\n",
    "slice_tensor = tf.cast(audio_slice, tf.float32) / 32768.0\n",
    "print(slice_tensor)\n",
    "# add a fade out at the start and end\n",
    "faded_tensor = tfio.audio.fade(slice_tensor, fade_in=1000, fade_out=1000, mode=\"logarithmic\")\n",
    "plt.figure()\n",
    "plt.plot(faded_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bdd42",
   "metadata": {},
   "source": [
    "Now we are going to create a spectrogram of our audio file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "560ee4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480000, 1, 257)\n",
      "(480000, 257)\n"
     ]
    }
   ],
   "source": [
    "fft_size = 512\n",
    "window_size = 512\n",
    "stride = 256\n",
    "\n",
    "spectrogram = tfio.audio.spectrogram(\n",
    "    faded_tensor, nfft=fft_size, window=window_size, stride=stride)\n",
    "print(spectrogram.shape)\n",
    "# remove an extra single dimension axis,\n",
    "# I am not sure where it comes from...\n",
    "squeezed_spectrogram = tf.squeeze(tf.math.log(spectrogram).numpy(), axis=[-2])\n",
    "print(squeezed_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f77394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[      -inf       -inf       -inf ...       -inf       -inf       -inf]\n",
      " [-24.486326 -24.486326 -24.486326 ... -24.486322 -24.486322 -24.486326]\n",
      " [-21.741388 -21.741388 -21.741388 ... -21.741385 -21.741385 -21.741388]\n",
      " ...\n",
      " [-18.680403 -18.680403 -18.680403 ... -18.680399 -18.680399 -18.680403]\n",
      " [-19.418322 -19.418322 -19.418322 ... -19.418318 -19.41832  -19.418322]\n",
      " [      -inf       -inf       -inf ...       -inf       -inf       -inf]], shape=(480000, 257), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae5ee4",
   "metadata": {},
   "source": [
    "Now lets plot our spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "12b7cacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15a611b10>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAAGiCAYAAACBNxqGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAQgklEQVR4nO3df0xV9R/H8feFy73A9HIh5OIPSArTKZqJSjdLWzIpWWVryzlqrpqmwaarmZJlqz/CWauVU9fWlNyad7mFNX8tBgL9UFQCBdFbLQtXAvkD8Ccg9/39wy9nHEC416AXwuux3Q3O+XjPx+eu957hxtuiqioEEYTewFDG+ECMD8T4QIwPxPhAjA/E+ECMD8T4QEMi/qZNm2Ts2LESGhoqKSkpcvjwYfSWbtJBzuPxqM1m061bt+qJEyd0yZIl6nQ6ta6uDr01HfTxZ86cqZmZmcb3bW1tOmrUKM3JyQHu6iYr+l9ef2ppaZGysjLJzs42jgUFBUlqaqocPHiwy/rm5mZpbm42vvf5fHL+/Hmx2WwyevRoCQrq23fpQf2ef+7cOWlraxOXy2U67nK5pLa2tsv6nJwciYiIMB6RkZGSmJgo8fHx8vfff/f5/gZ1/EBlZ2dLY2Oj8aipqTHODR8+vM+vN6jfdqKjoyU4OFjq6upMx+vq6iQ2NrbLervdLna7vdvnslgsfb6/Qf3Kt9lskpycLAUFBcYxn88nBQUF4na7gTv7P/Qnfn/zeDxqt9s1NzdXq6urdenSpep0OrW2trbXP9vY2KgioiKijY2Nfb63Qf22IyKycOFC+eeff2TdunVSW1srU6dOlf3793f5EEawqPI/0G+lqalJIiIiRESksbFRHA5Hnz7/oH7PH+gYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB+I8YEYH4jxgRgfiPGBGB8o4PglJSXy5JNPyqhRo8RisciuXbtM51VV1q1bJyNHjpSwsDBJTU2VX3/91bTmwoULkpGRIQ6HQ5xOp7z88sty+fJl05rjx4/LI488IqGhoRIXFycbNmzospedO3fKhAkTJDQ0VCZPnix79+4NeC9QgU642bt3r65du1a//vprFRHNy8sznV+/fr1GRETorl279NixY/rUU09pQkKCXrt2zVjz+OOP6/3336+HDh3S77//XhMTE3XRokXG+cbGRnW5XJqRkaFVVVW6Y8cODQsL088++8xY8+OPP2pwcLBu2LBBq6ur9a233tKQkBCtrKwMaC896e9pQf9qVFPn+D6fT2NjY/WDDz4wjjU0NKjdbtcdO3aoqmp1dbWKiB45csRYs2/fPrVYLPrXX3+pqurmzZs1MjJSm5ubjTWrV6/W8ePHG98/99xzmp6ebtpPSkqKvvLKK37vpTf9Hb9P3/NPnz4ttbW1kpqaahyLiIiQlJQUYxDkwYMHxel0yvTp0401qampEhQUJKWlpcaa2bNni81mM9akpaWJ1+uVixcvGms6Xqd9Tft1/NlLZ83NzdLU1GR69Kc+jd8+7LGnQZC1tbUSExNjOm+1WiUqKsq0prvn6HiNW63peL63vXTWeTBlXFycH3/r28e7nQ46D6Y8c+ZMv16vT+O3D3vsaRBkbGys1NfXm87fuHFDLly4YFrT3XN0vMat1nQ839teOrPb7eJwOEyP/tSn8RMSEiQ2NtY0CLKpqUlKS0uNQZBut1saGhqkrKzMWFNYWCg+n09SUlKMNSUlJdLa2mqsyc/Pl/Hjx0tkZKSxpuN12te0X8efvcAF+gl96dIlLS8v1/LychUR/eijj7S8vFz//PNPVb15e+d0OvWbb77R48eP69NPP93treYDDzygpaWl+sMPP+i4ceNMt5oNDQ3qcrn0hRde0KqqKvV4PBoeHt7lVtNqteqHH36oJ0+e1HfeeafbW83e9tKTAXereeDAAWNDHR+LFy9W1Zu3eG+//ba6XC612+06d+5c9Xq9puc4f/68Llq0SIcNG6YOh0NffPFFvXTpkmnNsWPH9OGHH1a73a6jR4/W9evXd9nLV199pffdd5/abDadNGmS7tmzx3Ten730pL/jczBlDziYchBjfCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8IMYHYnyggOLn5OTIjBkzZPjw4RITEyMLFiwQr9drWnP9+nXJzMyUu+66S4YNGybPPvtsl3FJNTU1kp6eLuHh4RITEyOrVq2SGzdumNYUFRXJtGnTxG63S2JiouTm5nbZz6ZNm2Ts2LESGhoqKSkpcvjw4YD3AhXIgJW0tDTdtm2bVlVVaUVFhc6fP1/j4+P18uXLxpply5ZpXFycFhQU6NGjR/XBBx/Uhx56yDh/48YNTUpK0tTUVC0vL9e9e/dqdHS0ZmdnG2t+//13DQ8P19dee02rq6t148aNGhwcrPv37zfWeDwetdlsunXrVj1x4oQuWbJEnU6n1tXV+b2X3gy4aUEd1dfXq4hocXGxqt4csRQSEqI7d+401pw8eVJFRA8ePKiqN6eKBgUFaW1trbFmy5Yt6nA4jEGUb7zxhk6aNMl0rYULF2paWprx/cyZMzUzM9P4vq2tTUeNGqU5OTl+76U3A3owZWNjo4iIREVFiYhIWVmZtLa2moZBTpgwQeLj402DKSdPnmyaWZiWliZNTU1y4sQJY01PQydbWlqkrKzMtCYoKEhSU1ONNf7spbM7ZjClz+eTlStXyqxZsyQpKUlEbg6DtNls4nQ6TWs7D4y83aGTTU1Ncu3aNTl37py0tbX1Opiyt710dscMpszMzJSqqirxeDx9uR+o/3owpfV2/lBWVpbs3r1bSkpKZMyYMcbx2NhYaWlpkYaGBtMrrvPAyM53Jf4OnXQ4HBIWFibBwcESHBzc62DK3vbSmd1uF7vdHkCJfyegV76qSlZWluTl5UlhYaEkJCSYzicnJ0tISIhpGKTX65WamhrTYMrKykrTZND8/HxxOBwyceJEY01PQydtNpskJyeb1vh8PikoKDDW+LMXuEA+nZcvX64RERFaVFSkZ8+eNR5Xr1411ixbtkzj4+O1sLBQjx49qm63W91ut3G+/VZz3rx5WlFRofv379cRI0Z0e6u5atUqPXnypG7atKnbW0273a65ublaXV2tS5cuVafTabqL6m0vvRlQt5rSzUBKEdFt27YZa65du6avvvqqRkZGanh4uD7zzDN69uxZ0/P88ccf+sQTT2hYWJhGR0fr66+/rq2traY1Bw4c0KlTp6rNZtN77rnHdI12Gzdu1Pj4eLXZbDpz5kw9dOiQ6bw/e+kJB1MCcTDlIMb4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+ECMD8T4QIwPxPhAjA/E+EABxd+yZYtMmTJFHA6HOBwOcbvdsm/fPuM8h1IGKJABK99++63u2bNHf/nlF/V6vfrmm29qSEiIVlVVqergGkqpOsCmBXUnMjJSP//880E3lFJ1AA+mbGtrE4/HI1euXBG3233HD6UUuQMGU1ZWVsqwYcPEbrfLsmXLJC8vTyZOnHjHD6UUuQMGU44fP14qKiqktLRUli9fLosXL5bq6ur+2Nt/bsAPprTZbJKYmCgiN+cPHjlyRD755BNZuHDhHT2UUmSAD6bsjs/nk+bmZg6lvB2BfDqvWbNGi4uL9fTp03r8+HFds2aNWiwW/e6771R1cA2lVB1gt5ovvfSS3n333Wqz2XTEiBE6d+5cI7zq4BpKqcrBlFAcTDmIMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+0L+Kv379erFYLLJy5UrjGIdTBuB2h60cPnxYx44dq1OmTNEVK1YYxwfTcMoBNS2o3aVLl3TcuHGan5+vc+bMMeIPtuGUA3IwZWZmpqSnp3cZIHmnD6f8rwdTBjyez+PxyM8//yxHjhzpcu6/Gk558eLFWw6nPHXqlN976SwnJ0fefffdHv72fSugV/6ZM2dkxYoV8uWXX0poaGh/7Qnmvx5MGVD8srIyqa+vl2nTponVahWr1SrFxcXy6aefitVqFZfLZQyE7Kjz0Mjuhkq2n+tpTftwyujo6ICGU95qTWd2u90YMd7+6E8BxZ87d65UVlZKRUWF8Zg+fbpkZGQYX3M4ZQD+7Sd2x7sd1cE1nHJA3mp21Dn+YBpOycGUQBxMOYgxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMT4Q4wMxPhDjAzE+EOMDMX4POv7ixf74JYyM34Pz5893+3VfYfweREVFdft1X2H8HgQFBXX7dZ89f58/I/mN8YECnhwxlNjtdlm7dq3xdV/jL7IG4tsOEOMDMT4Q4wMxPtCQi5+TkyMzZsyQ4cOHS0xMjCxYsEC8Xq9pzaOPPioWi8X0iImJMQ2+9Ge4Zm+GXPzi4mLJzMyUQ4cOSX5+vrS2tsq8efPkypUrpnWPPfaYhISEyMcffyxFRUUyf/58SUtLk/r6emlra5P09HRpaWmRn376Sb744gvJzc2VdevWBbaZPh+Bc4epr69XEdHi4mLj2Jw5c9Tlct1y8KU/wzX9MeRe+Z01NjaKiPmnlqoqdXV1sn37dklKSpLs7Gy5fv26MfjSn+Ga/hjSP17w+XyycuVKmTVrliQlJRnH09PTpaSkRDZv3iwWi0VWr14tXq9XEhMT5dSpU+JyuXodrumPIf3Kz8zMlKqqKvF4PKbjzz//vIiI3HvvvZKRkSHbt2+XvLw8uXjxYp9ef8jGz8rKkt27d8uBAwdkzJgxpnOdB1+mpKSIiMjp06clNjbWr+Ga/hhy8VVVsrKyJC8vTwoLCyUhIaHLms6DLysqKkREpLKyUtxut1/DNf3dzJCyfPlyjYiI0KKiIj179qzxuHr1qqqq/vbbb/ree+/p+++/rzabTVesWKFxcXE6cuRIY/ClP8M1/THk4sv/B012frQPvqypqdHZs2drVFSUWq1WtVqtGhQUpMnJyabBl/4M1+wNf54PNOTe8wcSxgdifCDGB2J8IMYHYnwgxgdifCDGB2J8oP8BdFo9Amat9bwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# derr there is something wrong with how this displays....\n",
    "plt.figure()\n",
    "plt.imshow(squeezed_spectrogram)\n",
    "# plt.specgram(spectrogram[0], NFFT=fft_size, window=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d72b5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRigAAABXQVZFZm10IBAAAAABAAEAgLsAAAB3AQACABAAZGF0YQQAAAAAAAAA\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio(faded_tensor[:1].numpy(), rate=audio.rate.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "396e84be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slice_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m      3\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m      5\u001b[0m tfio\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mspectrogram(\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mslice_tensor\u001b[49m, fft_size, window_size, stride)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slice_tensor' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9b1ca843",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1102, in __len__\n\nTypeError: Scalar tensor has no `len()`\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Playback the audio file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# save the tensor as a string that can be saved as a .wav file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# unable to encode as the tensor is an int tensor and not a float tensor\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_wav\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_audio_ops.py:299\u001b[0m, in \u001b[0;36mencode_wav\u001b[0;34m(audio, sample_rate, name)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_audio_ops.py:342\u001b[0m, in \u001b[0;36mencode_wav_eager_fallback\u001b[0;34m(audio, sample_rate, name, ctx)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1636\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1627\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1628\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1629\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1633\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1636\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1639\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1102, in __len__\n\nTypeError: Scalar tensor has no `len()`\n\n"
     ]
    }
   ],
   "source": [
    "#Playback the audio file\n",
    "\n",
    "# save the tensor as a string that can be saved as a .wav file\n",
    "# unable to encode as the tensor is an int tensor and not a float tensor\n",
    "tf.audio.encode_wav(\n",
    "    audio_slice, sample_rate, name=\"test.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b8929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3f48eefe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AudioIOTensor' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m(), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(audio)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AudioIOTensor' object has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "t = np.arange(0, audio.len(), 1)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2)\n",
    "plt.plot(audio)\n",
    "plt.spectrogram(audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "da561865",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'spectrogram'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectrogram\u001b[49m(audio);\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'spectrogram'"
     ]
    }
   ],
   "source": [
    "plt.spectrogram(audio);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3523904f-4b7e-45f1-9af9-fd1daa93016b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConversionError",
     "evalue": "converting /Users/nathan/workspace/tensor_flow_projects/audio_experiments/tronica_trimmed.wav: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:771\u001b[0m, in \u001b[0;36mto_graph\u001b[0;34m(entity, recursive, experimental_optional_features)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:265\u001b[0m, in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConversionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:774\u001b[0m, in \u001b[0;36mto_graph\u001b[0;34m(entity, recursive, experimental_optional_features)\u001b[0m\n",
      "\u001b[0;31mConversionError\u001b[0m: converting /Users/nathan/workspace/tensor_flow_projects/audio_experiments/tronica_trimmed.wav: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead."
     ]
    }
   ],
   "source": [
    "tf.autograph.to_graph(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c85c4d4d-f78a-499d-9422-63304acf1bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 14:54:39.323892: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at decode_wav_op.cc:55 : INVALID_ARGUMENT: Header mismatch: Expected RIFF but found /Use\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__DecodeWav_device_/job:localhost/replica:0/task:0/device:CPU:0}} Header mismatch: Expected RIFF but found /Use [Op:DecodeWav]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_wav\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(audio2)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_audio_ops.py:187\u001b[0m, in \u001b[0;36mdecode_wav\u001b[0;34m(contents, desired_channels, desired_samples, name)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_audio_ops.py:251\u001b[0m, in \u001b[0;36mdecode_wav_eager_fallback\u001b[0;34m(contents, desired_channels, desired_samples, name, ctx)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__DecodeWav_device_/job:localhost/replica:0/task:0/device:CPU:0}} Header mismatch: Expected RIFF but found /Use [Op:DecodeWav]"
     ]
    }
   ],
   "source": [
    "audio2 = tf.audio.decode_wav(\n",
    "    contents, desired_channels=2\n",
    ")\n",
    "print(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08429b-0be0-4101-b797-3e738ea96b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01f0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a38df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11079927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
