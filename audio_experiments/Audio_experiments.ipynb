{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969bd85a-898b-45eb-a05e-a0ef08b94b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 08:56:25.152831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99532a8-22da-454e-a8f0-0db5be2c1ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = 'audio_experiments/tronica_trimmed.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3951061c-5fb4-49b7-bbac-633e22e13f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AudioIOTensor: shape=[2425819       2], dtype=<dtype: 'int16'>, rate=48000>\n"
     ]
    }
   ],
   "source": [
    "# read the audio file into an IOTensor\n",
    "audio = tfio.audio.AudioIOTensor(contents)\n",
    "print(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3523904f-4b7e-45f1-9af9-fd1daa93016b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConversionError",
     "evalue": "converting <AudioIOTensor: shape=[2425819       2], dtype=<dtype: 'int16'>, rate=48000>: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:771\u001b[0m, in \u001b[0;36mto_graph\u001b[0;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[1;32m    766\u001b[0m   program_ctx \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mProgramContext(\n\u001b[1;32m    767\u001b[0m       options\u001b[38;5;241m=\u001b[39mconverter\u001b[38;5;241m.\u001b[39mConversionOptions(\n\u001b[1;32m    768\u001b[0m           recursive\u001b[38;5;241m=\u001b[39mrecursive,\n\u001b[1;32m    769\u001b[0m           user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    770\u001b[0m           optional_features\u001b[38;5;241m=\u001b[39mexperimental_optional_features))\n\u001b[0;32m--> 771\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m autograph_artifact(\u001b[43m_convert_actual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram_ctx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mNameError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:265\u001b[0m, in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(entity, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 265\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply autograph to a function that doesn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m try passing f.python_function instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    269\u001b[0m transformed, module, source_map \u001b[38;5;241m=\u001b[39m _TRANSPILER\u001b[38;5;241m.\u001b[39mtransform(entity, program_ctx)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConversionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:774\u001b[0m, in \u001b[0;36mto_graph\u001b[0;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mNameError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    773\u001b[0m   logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError converting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, entity, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 774\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ConversionError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverting \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    775\u001b[0m       entity, e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[0;31mConversionError\u001b[0m: converting <AudioIOTensor: shape=[2425819       2], dtype=<dtype: 'int16'>, rate=48000>: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead."
     ]
    }
   ],
   "source": [
    "tf.autograph.to_graph(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85c4d4d-f78a-499d-9422-63304acf1bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 09:07:39.321060: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at decode_wav_op.cc:55 : INVALID_ARGUMENT: Header mismatch: Expected RIFF but found tron\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__DecodeWav_device_/job:localhost/replica:0/task:0/device:CPU:0}} Header mismatch: Expected RIFF but found tron [Op:DecodeWav]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_wav\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(audio2)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_audio_ops.py:187\u001b[0m, in \u001b[0;36mdecode_wav\u001b[0;34m(contents, desired_channels, desired_samples, name)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m--> 187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_wav_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesired_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdesired_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesired_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m    191\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_audio_ops.py:251\u001b[0m, in \u001b[0;36mdecode_wav_eager_fallback\u001b[0;34m(contents, desired_channels, desired_samples, name, ctx)\u001b[0m\n\u001b[1;32m    248\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [contents]\n\u001b[1;32m    249\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesired_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m, desired_channels, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesired_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    250\u001b[0m desired_samples)\n\u001b[0;32m--> 251\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDecodeWav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[1;32m    254\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[1;32m    255\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecodeWav\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__DecodeWav_device_/job:localhost/replica:0/task:0/device:CPU:0}} Header mismatch: Expected RIFF but found tron [Op:DecodeWav]"
     ]
    }
   ],
   "source": [
    "audio2 = tf.audio.decode_wav(\n",
    "    contents, desired_channels=2\n",
    ")\n",
    "print(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08429b-0be0-4101-b797-3e738ea96b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
