{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "969bd85a-898b-45eb-a05e-a0ef08b94b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tensorflow_io provides extended data formats and\n",
    "# the ability to stream data\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio\n",
    "# Import AudioSegment from pydub\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play as playAudio\n",
    "import keyboard\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37650d80",
   "metadata": {},
   "source": [
    "## Establish our Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b99532a8-22da-454e-a8f0-0db5be2c1ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples in slice:  480000\n"
     ]
    }
   ],
   "source": [
    "file_paths = [os.getcwd() + '/tronica_trimmed.wav', os.getcwd() + '/2023_01_11_rocktronica_AE.wav']\n",
    "sample_rate = 48000\n",
    "# in number of seconds\n",
    "slice_length = 10\n",
    "# number of samples we will use for our slices\n",
    "s_len = sample_rate*slice_length\n",
    "print(\"samples in slice: \", s_len)\n",
    "audio_segments = []\n",
    "\n",
    "# load the file and play it as a sanity check...\n",
    "ittr = 0\n",
    "for path in file_paths:\n",
    "      audio_segments.append(AudioSegment.from_wav(path))\n",
    "      playAudio(audio_segments[ittr])\n",
    "      ittr = ittr + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ef55072",
   "metadata": {},
   "source": [
    "## Generally we want to work with mono audio\n",
    " Below code will take the sample and split it into two Mono samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc214de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "# Open the stereo audio file as\n",
    "# an AudioSegment instance\n",
    "\"\"\"\n",
    "def loadMonoAudioIoTensorFromeStereoFile(path):\n",
    "    stereo_audio = AudioSegment.from_file(\n",
    "        path,\n",
    "        format=\"wav\")\n",
    "    # read the audio file into an IOTensor\n",
    "    # stereo_io_tensor = tfio.audio.AudioIOTensor(contents)\n",
    "    # slice the audio tensor into a bunch of tensors that are each 10 seconds long\n",
    "    mono_audio = stereo_audio.split_to_mono()\n",
    "    print(type(mono_audio), len(mono_audio))\n",
    "    print(mono_audio)\n",
    "    return mono_audio\n",
    "\n",
    "mono_audio = loadMonoAudioIoTensorFromeStereoFile(file_path)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04cb10fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathan/workspace/tensor_flow_projects/audio_experiments/2023_01_11_rocktronica_AE_left.wav\n",
      "/Users/nathan/workspace/tensor_flow_projects/audio_experiments/2023_01_11_rocktronica_AE_right.wav\n",
      "<class '_io.BufferedRandom'> <_io.BufferedRandom name='/Users/nathan/workspace/tensor_flow_projects/audio_experiments/2023_01_11_rocktronica_AE_left.wav'>\n"
     ]
    }
   ],
   "source": [
    "# instead lets both load, split, and save stereo files as mono =)\n",
    "def createMonoFilesFromStereo(path):\n",
    "    stereo_audio = AudioSegment.from_file(\n",
    "            path,\n",
    "            format=\"wav\")\n",
    "    # Calling the split_to_mono method\n",
    "    # on the stereo audio file\n",
    "    mono_audios = stereo_audio.split_to_mono()\n",
    "    \n",
    "    # Exporting/Saving the two mono\n",
    "    # audio files present at index 0(left)\n",
    "    # and index 1(right) of list returned\n",
    "    # by split_to_mono method\n",
    "    left_path = path[:-4]+\"_left.wav\"\n",
    "    right_path = path[:-4]+\"_right.wav\"\n",
    "    print(left_path)\n",
    "    print(right_path)\n",
    "    mono_left = mono_audios[0].export(\n",
    "        left_path,\n",
    "        format=\"wav\")\n",
    "    mono_right = mono_audios[1].export(\n",
    "        right_path,\n",
    "        format=\"wav\")\n",
    "    return mono_left, mono_right\n",
    "\n",
    "# run the function on our stereo file, and save the two mono audio io tensors \n",
    "left_channel, right_channel = createMonoFilesFromStereo(file_paths[1])\n",
    "print(type(left_channel), left_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0e7b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_io.python.ops.audio_ops.AudioIOTensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/Users/nathan/workspace/tensor_flow_projects/tensor_venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1102, in __len__\n    raise TypeError(\"Scalar tensor has no `len()`\")\n\nTypeError: Scalar tensor has no `len()`\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m audio_tensors\u001b[39m.\u001b[39mappend(tfio\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mAudioIOTensor(file_paths[\u001b[39m0\u001b[39m]))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(audio_tensors[\u001b[39m0\u001b[39m]))\n\u001b[0;32m----> 4\u001b[0m slice_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcast(audio_tensors[\u001b[39m0\u001b[39;49m], tf\u001b[39m.\u001b[39;49mfloat32) \u001b[39m/\u001b[39m \u001b[39m32768.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(slice_tensor)\n\u001b[1;32m      6\u001b[0m \u001b[39m# add a fade out at the start and end\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/tensor_flow_projects/tensor_venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/workspace/tensor_flow_projects/tensor_venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/Users/nathan/workspace/tensor_flow_projects/tensor_venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1102, in __len__\n    raise TypeError(\"Scalar tensor has no `len()`\")\n\nTypeError: Scalar tensor has no `len()`\n\n"
     ]
    }
   ],
   "source": [
    "audio_tensors = []\n",
    "audio_tensors.append(tfio.audio.AudioIOTensor(file_paths[0]))\n",
    "print(type(audio_tensors[0]))\n",
    "slice_tensor = tf.cast(audio_tensors[0], tf.float32) / 32768.0\n",
    "print(slice_tensor)\n",
    "# add a fade out at the start and end\n",
    "faded_tensor = tfio.audio.fade(slice_tensor, fade_in=1000, fade_out=1000, mode=\"logarithmic\")\n",
    "plt.figure()\n",
    "plt.plot(faded_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bdd42",
   "metadata": {},
   "source": [
    "Now we are going to create a spectrogram of our audio file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_size = 512\n",
    "window_size = 512\n",
    "stride = 256\n",
    "\n",
    "spectrogram = tfio.audio.spectrogram(\n",
    "    faded_tensor, nfft=fft_size, window=window_size, stride=stride)\n",
    "print(spectrogram.shape)\n",
    "# remove an extra single dimension axis,\n",
    "# I am not sure where it comes from...\n",
    "squeezed_spectrogram = tf.squeeze(tf.math.log(spectrogram).numpy(), axis=[-2])\n",
    "print(squeezed_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae5ee4",
   "metadata": {},
   "source": [
    "Now lets plot our spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derr there is something wrong with how this displays....\n",
    "plt.figure()\n",
    "plt.imshow(squeezed_spectrogram)\n",
    "# plt.specgram(spectrogram[0], NFFT=fft_size, window=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(faded_tensor[:1].numpy(), rate=audio.rate.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e84be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ca843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playback the audio file\n",
    "\n",
    "# save the tensor as a string that can be saved as a .wav file\n",
    "# unable to encode as the tensor is an int tensor and not a float tensor\n",
    "tf.audio.encode_wav(\n",
    "    audio_slice, sample_rate, name=\"test.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b8929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, audio.len(), 1)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2)\n",
    "plt.plot(audio)\n",
    "plt.spectrogram(audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da561865",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spectrogram(audio);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523904f-4b7e-45f1-9af9-fd1daa93016b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.autograph.to_graph(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c4d4d-f78a-499d-9422-63304acf1bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio2 = tf.audio.decode_wav(\n",
    "    contents, desired_channels=2\n",
    ")\n",
    "print(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08429b-0be0-4101-b797-3e738ea96b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01f0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a38df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11079927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3655ac51d38ab7348615ff741009be41ced8003e01376576c0c8296826e6db1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
